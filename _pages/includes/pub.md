# üìù Selected Publications  

For a complete list of publications, please visit my [Google Scholar profile](https://scholar.google.com/citations?user=hCvlj5cAAAAJ&hl=en&oi=ao) [![](https://img.shields.io/badge/citations-350+-blue?logo=google-scholar&logoColor=white)](https://scholar.google.com/citations?user=hCvlj5cAAAAJ&hl=en&oi=ao)

<!-- Âä®ÊÄÅÂºïÁî®ÂæΩÁ´†ÔºàÂ∑≤Ê≥®ÈáäÔºâ
[![](https://img.shields.io/badge/dynamic/json?logo=google-scholar&logoColor=white&label=citations&query=citedby&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fydchen0806%2Fydchen0806.github.io@google-scholar-stats%2Fgs_data.json)](https://scholar.google.com/citations?user=hCvlj5cAAAAJ&hl=en&oi=ao)
-->

## Journal Articles

**Note:** * denotes equal contribution

<div class='paper-box'><div class='paper-box-image'><div><img src='images/JBHI25.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[EMPOWER: Evolutionary Medical Prompt Optimization With Reinforcement Learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11205280) \\
IEEE Journal of Biomedical and Health Informatics | 2025 \\
**Chen, Yinda\***; **He, Yangfan\***; Yang, Jing; Zhang, Dapeng; Yuan, Zhenlong; Khan, Muhammad Attique; Baili, Jamel; Yee, Por Lip

This paper introduces EMPOWER, a novel evolutionary framework that enhances medical prompt quality through specialized representation learning, multi-dimensional evaluation, and structure-preserving algorithms for Large Language Models in healthcare applications. The framework achieves 24.7% reduction in factually incorrect content, 19.6% enhancement in domain specificity, and 15.3% higher clinician preference in blinded evaluations, facilitating more responsible integration of LLMs into healthcare settings.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/TMI24.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Unsupervised Domain Adaptation for EM Image Denoising with Invertible Networks](/docs/Unsupervised_Domain_Adaptation_for_EM_Image_Denoising_With_Invertible_Networks.pdf) \\
TMI | July 29, 2024 \\
Deng, Shiyu; **Chen, Yinda**; Huang, Wei; Zhang, Ruobing; Xiong, Zhiwei

[**Code**](https://github.com/sydeng99/DADn) [![](https://img.shields.io/github/stars/sydeng99/DADn?style=social&label=Code+Stars)](https://github.com/sydeng99/DADn)

The paper proposes an unsupervised domain adaptation method for EM image denoising with invertible networks, outperforming existing methods.

</div>
</div>

## Conference Papers

**Note:** * denotes equal contribution

<div class='paper-box'><div class='paper-box-image'><div><img src='images/ICCV25.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[TokenUnify: Scaling Up Autoregressive Pretraining for Neuron Segmentation](https://openaccess.thecvf.com/content/ICCV2025/papers/Chen_TokenUnify_Scaling_Up_Autoregressive_Pretraining_for_Neuron_Segmentation_ICCV_2025_paper.pdf) \\
ICCV | October 25, 2025 \\
**Chen, Yinda\***; **Shi, Haoyuan\***; Liu, Xiaoyu; Shi, Te; Zhang, Ruobing; Liu, Dong; Xiong, Zhiwei; Wu, Feng

[**Code**](https://github.com/ydchen0806/TokenUnify) [![](https://img.shields.io/github/stars/ydchen0806/TokenUnify?style=social&label=Code+Stars)](https://github.com/ydchen0806/TokenUnify) | [**Dataset**](https://huggingface.co/datasets/cyd0806/wafer_EM) [![](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Dataset-blue)](https://huggingface.co/datasets/cyd0806/wafer_EM) | [**Weights**](https://huggingface.co/cyd0806/TokenUnify/tree/main/Pretrained_weights) [![](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Weights-yellow)](https://huggingface.co/cyd0806/TokenUnify/tree/main/Pretrained_weights)

TokenUnify proposes a hierarchical predictive coding framework that unifies random token, next-token, and next-all token prediction for neuron segmentation from electron microscopy. The method reduces autoregressive error accumulation from O(K) to O(‚àöK) and introduces a large-scale EM dataset with 1.2 billion annotated voxels. Leveraging Mamba architecture, it achieves 44% improvement over training from scratch and outperforms MAE by 25%.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/AAAI25.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Condition-generation Latent Coding with an External Dictionary for Deep Image Compression](/docs/Condition_generation_Latent_Coding_with_an_External_Dictionary_for_Deep_Image_Compression.pdf) \\
AAAI (oral) | March 06, 2025 \\
Wu, Siqi; **Chen, Yinda\***; Liu, Dong; He, Zhihai

[**Code**](https://github.com/ydchen0806/CLC) [![](https://img.shields.io/github/stars/ydchen0806/CLC?style=social&label=Code+Stars)](https://github.com/ydchen0806/CLC)

The paper proposes CLC for deep image compression. It uses a dictionary to generate references, shows good performance, and has theoretical analysis.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/NeurIPS24.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MaskFactory: Towards High-quality Synthetic Data Generation for Dichotomous Image Segmentation](https://arxiv.org/pdf/2412.19080) \\
NeurIPS | October 17, 2024 \\
Qian, Haotian; **Chen, Yinda\***; Lou, Shengtao; Khan, Fahad Shahbaz; Jin, Xiaogang; Fan, Deng-Ping

[**Project**](https://qian-hao-tian.github.io/MaskFactory/) | [**Code**](https://github.com/ydchen0806/MaskFactory) [![](https://img.shields.io/github/stars/ydchen0806/MaskFactory?style=social&label=Code+Stars)](https://github.com/ydchen0806/MaskFactory)

MaskFactory proposes a two-stage method to generate high-quality synthetic datasets for DIS, outperforming existing methods in quality and efficiency.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/MICCAI24.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[BIMCV-R: A Landmark Dataset for 3D CT Text-Image Retrieval](https://arxiv.org/pdf/2403.15992) \\
MICCAI | October 06, 2024 \\
**Chen, Yinda**; Liu, Che; Liu, Xiaoyu; Arcucci, Rossella; Xiong, Zhiwei

[**Dataset**](https://huggingface.co/datasets/cyd0806/BIMCV-R) [![](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Dataset-blue)](https://huggingface.co/datasets/cyd0806/BIMCV-R)

This paper presents BIMCV-R, a 3D CT text-image retrieval dataset, and MedFinder. Tests show MedFinder outperforms baselines in related tasks.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/ICASSP24.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Learning multiscale consistency for self-supervised electron microscopy instance segmentation](https://arxiv.org/pdf/2308.09917) \\
ICASSP | April 13, 2024 \\
**Chen, Yinda**; Huang, Wei; Liu, Xiaoyu; Deng, Shiyu; Chen, Qi; Xiong, Zhiwei

[**Code**](https://github.com/ydchen0806/MS-Con-EM-Seg) [![](https://img.shields.io/github/stars/ydchen0806/MS-Con-EM-Seg?style=social&label=Code+Stars)](https://github.com/ydchen0806/MS-Con-EM-Seg)

A pretraining framework for EM volume instance segmentation is proposed. It enforces multiscale consistency and shows good performance in neuron and mitochondria segmentation.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/ijcai2023.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">


[Self-Supervised Neuron Segmentation with Multi-Agent Reinforcement Learning](https://www.ijcai.org/proceedings/2023/0068.pdf) \\
IJCAI (oral) | August 17, 2023 \\
**Chen, Yinda** ; Huang, Wei ; Zhou, Shenglong ; Chen, Qi ; Xiong, Zhiwei  
[**Code**](https://github.com/ydchen0806/dbMiM) [![](https://img.shields.io/github/stars/ydchen0806/dbMiM?style=social&label=Code+Stars)](https://github.com/ydchen0806/dbMiM)

This paper proposes a decision - based MIM for neuron segmentation in EM data. It uses MARL to optimize masking, outperforming alternatives.  
</div>
</div>

<!-- ## Research Highlights  
#### **Neuron Segmentation and Brain Tissue Reconstruction**  
- **Principal Investigator**, Ph.D. Natural Science Foundation Project (2025.1 ‚Äì 2027.12)  
  - Developed a billion-scale brain neuron segmentation model with advanced masking and point cloud alignment techniques.  

#### **Self-Supervised Pretraining**  
- **Key Contributions:**  
  - *Self-supervised Neuron Segmentation with Multi-Agent Reinforcement Learning* (IJCAI 2023, Oral): Enhanced MAE masking with reinforcement learning.  
  - *Learning Multiscale Consistency for Electron Microscopy Segmentation* (ICASSP 2024): Introduced multiscale contrastive learning and feature reconstruction.  

#### **Multimodal Data Compression and Retrieval**  
- *Conditional Latent Coding for Image Compression* (AAAI 2025, Oral): Improved entropy models with retrieval-based approaches.  
- *UniCompress: Multimodal Medical Image Compression* (Submitted to ICML 2025): Proposed a knowledge distillation-based compression framework.  

#### **Large Model Pretraining**  
- Specialized in pretraining medical image and neuron segmentation models using large-scale GPU clusters (64-GPU A40, DDP, DeepSpeed). -->
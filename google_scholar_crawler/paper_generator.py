#!/usr/bin/env python3
"""
è®ºæ–‡ä¿¡æ¯è‡ªåŠ¨ç”Ÿæˆå™¨
ä» Google Scholar è·å–è®ºæ–‡ä¿¡æ¯ï¼Œç”Ÿæˆ pub.md æ ¼å¼çš„å†…å®¹

åŠŸèƒ½ï¼š
1. è·å–ä¸€ä½œ/å…±ä¸€è®ºæ–‡çš„è¯¦ç»†ä¿¡æ¯
2. è‡ªåŠ¨è¯†åˆ«ä¼šè®®/æœŸåˆŠç­‰çº§ï¼ˆCCF åˆ†åŒºã€SCI åˆ†åŒºï¼‰
3. ç­›é€‰é«˜å¼•ç”¨è®ºæ–‡ï¼ˆ>=50ï¼‰
4. ç”Ÿæˆ Markdown æ ¼å¼çš„è®ºæ–‡åˆ—è¡¨
"""
import json
import os
import re
import sys
from datetime import datetime

try:
    import requests
except ImportError:
    print("è¯·å®‰è£… requests: pip install requests")
    sys.exit(1)

from venue_config import CCF_VENUES, SCI_JOURNALS, get_venue_level, is_qualified_venue


# ä½œè€…å§“åå˜ä½“
AUTHOR_NAME_VARIANTS = [
    "Yinda Chen",
    "Y Chen",
    "YD Chen",
    "é™ˆèƒ¤è¾¾",
]

# ä¼šè®®/æœŸåˆŠç®€ç§°æ˜ å°„
VENUE_SHORTCUTS = {
    # CCF A ä¼šè®®
    "AAAI": {"full": "AAAI Conference on Artificial Intelligence", "type": "conference", "ccf": "A"},
    "NeurIPS": {"full": "Neural Information Processing Systems", "type": "conference", "ccf": "A"},
    "NIPS": {"full": "Neural Information Processing Systems", "type": "conference", "ccf": "A"},
    "ICML": {"full": "International Conference on Machine Learning", "type": "conference", "ccf": "A"},
    "ICLR": {"full": "International Conference on Learning Representations", "type": "conference", "ccf": "A"},
    "CVPR": {"full": "IEEE/CVF Conference on Computer Vision and Pattern Recognition", "type": "conference", "ccf": "A"},
    "ICCV": {"full": "IEEE/CVF International Conference on Computer Vision", "type": "conference", "ccf": "A"},
    "ECCV": {"full": "European Conference on Computer Vision", "type": "conference", "ccf": "A"},
    "ACL": {"full": "Annual Meeting of the Association for Computational Linguistics", "type": "conference", "ccf": "A"},
    "IJCAI": {"full": "International Joint Conference on Artificial Intelligence", "type": "conference", "ccf": "A"},
    
    # CCF B ä¼šè®®
    "MICCAI": {"full": "Medical Image Computing and Computer Assisted Intervention", "type": "conference", "ccf": "B"},
    "WACV": {"full": "IEEE/CVF Winter Conference on Applications of Computer Vision", "type": "conference", "ccf": "B"},
    "ACCV": {"full": "Asian Conference on Computer Vision", "type": "conference", "ccf": "B"},
    "ICASSP": {"full": "IEEE International Conference on Acoustics, Speech and Signal Processing", "type": "conference", "ccf": "B"},
    
    # Q1 æœŸåˆŠ
    "TPAMI": {"full": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "type": "journal", "sci": "Q1", "if": 23.6},
    "IJCV": {"full": "International Journal of Computer Vision", "type": "journal", "sci": "Q1", "if": 19.5},
    "TIP": {"full": "IEEE Transactions on Image Processing", "type": "journal", "sci": "Q1", "if": 10.6},
    "TMI": {"full": "IEEE Transactions on Medical Imaging", "type": "journal", "sci": "Q1", "if": 10.6},
    "TCSVT": {"full": "IEEE Transactions on Circuits and Systems for Video Technology", "type": "journal", "sci": "Q1", "if": 8.4},
    "MIA": {"full": "Medical Image Analysis", "type": "journal", "sci": "Q1", "if": 10.9},
    "TNNLS": {"full": "IEEE Transactions on Neural Networks and Learning Systems", "type": "journal", "sci": "Q1", "if": 10.4},
    
    # Q2 æœŸåˆŠ
    "JBHI": {"full": "IEEE Journal of Biomedical and Health Informatics", "type": "journal", "sci": "Q2", "if": 7.7},
    "PR": {"full": "Pattern Recognition", "type": "journal", "sci": "Q1", "if": 8.0},
    "NEUCOM": {"full": "Neurocomputing", "type": "journal", "sci": "Q2", "if": 6.0},
}


def detect_venue_from_text(text: str) -> dict:
    """
    ä»æ–‡æœ¬ä¸­æ£€æµ‹ä¼šè®®/æœŸåˆŠä¿¡æ¯
    """
    text_upper = text.upper()
    
    for shortcut, info in VENUE_SHORTCUTS.items():
        if shortcut.upper() in text_upper:
            return {
                "shortcut": shortcut,
                "full_name": info["full"],
                "type": info["type"],
                "ccf": info.get("ccf"),
                "sci": info.get("sci"),
                "impact_factor": info.get("if")
            }
    
    return None


def is_first_author(authors_str: str) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºä¸€ä½œï¼ˆåŒ…æ‹¬å…±åŒä¸€ä½œï¼‰
    """
    if not authors_str:
        return False
    
    # è·å–å‰ä¸¤ä¸ªä½œè€…
    authors = [a.strip() for a in authors_str.split(",")[:2]]
    
    for author in authors:
        for variant in AUTHOR_NAME_VARIANTS:
            if variant.lower() in author.lower():
                return True
            # æ£€æŸ¥å…±åŒä¸€ä½œæ ‡è®°
            if f"{variant}*" in authors_str or f"*{variant}" in authors_str:
                return True
    
    return False


def get_author_articles(scholar_id: str, api_key: str, num: int = 100) -> list:
    """
    è·å–ä½œè€…çš„è®ºæ–‡åˆ—è¡¨ï¼ˆåŒ…å«è¯¦ç»†ä¿¡æ¯ï¼‰
    """
    print(f"[SerpAPI] æ­£åœ¨è·å–è®ºæ–‡åˆ—è¡¨...")
    
    url = "https://serpapi.com/search.json"
    params = {
        "engine": "google_scholar_author",
        "author_id": scholar_id,
        "api_key": api_key,
        "hl": "en",
        "num": num,
        "sort": "pubdate"  # æŒ‰å‘è¡¨æ—¶é—´æ’åº
    }
    
    try:
        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        if "error" in data:
            print(f"[SerpAPI] API é”™è¯¯: {data['error']}")
            return []
        
        articles = data.get("articles", [])
        print(f"[SerpAPI] è·å–åˆ° {len(articles)} ç¯‡è®ºæ–‡")
        return articles
        
    except Exception as e:
        print(f"[SerpAPI] è·å–è®ºæ–‡å¤±è´¥: {e}")
        return []


def process_papers(articles: list) -> list:
    """
    å¤„ç†è®ºæ–‡åˆ—è¡¨ï¼Œæå–è¯¦ç»†ä¿¡æ¯
    """
    processed = []
    current_year = datetime.now().year
    
    for article in articles:
        title = article.get("title", "")
        authors = article.get("authors", "")
        year = article.get("year", "")
        cited_by = article.get("cited_by") or {}
        citations = cited_by.get("value", 0) if isinstance(cited_by, dict) else 0
        citations = citations or 0  # ç¡®ä¿ä¸æ˜¯ None
        link = article.get("link", "")
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºä¸€ä½œ
        first_author = is_first_author(authors)
        
        # æ£€æµ‹ä¼šè®®/æœŸåˆŠ
        venue_info = detect_venue_from_text(title + " " + str(article))
        
        # è®¡ç®—å¹´ä»½
        try:
            paper_year = int(year) if year else 0
        except ValueError:
            paper_year = 0
        
        # åˆ¤æ–­æ˜¯å¦ç¬¦åˆæ¡ä»¶
        is_high_cited = citations >= 50
        is_recent = paper_year >= current_year - 3
        is_qualified_ccf = venue_info and venue_info.get("ccf") in ["A", "B"]
        is_qualified_sci = venue_info and venue_info.get("sci") in ["Q1", "Q2"]
        
        paper_data = {
            "title": title,
            "authors": authors,
            "year": year,
            "citations": citations,
            "link": link,
            "is_first_author": first_author,
            "venue": venue_info,
            "is_high_cited": is_high_cited,
            "is_recent": is_recent,
            "is_qualified": is_qualified_ccf or is_qualified_sci,
            "should_include": first_author and (is_high_cited or (is_recent and (is_qualified_ccf or is_qualified_sci)))
        }
        
        processed.append(paper_data)
    
    return processed


def generate_paper_markdown(paper: dict) -> str:
    """
    ç”Ÿæˆå•ç¯‡è®ºæ–‡çš„ Markdown æ ¼å¼
    """
    title = paper["title"]
    authors = paper["authors"]
    year = paper["year"]
    citations = paper["citations"]
    link = paper["link"]
    venue = paper.get("venue", {})
    
    # ç”Ÿæˆä¼šè®®/æœŸåˆŠå¾½ç« 
    venue_badge = ""
    ccf_badge = ""
    
    if venue:
        shortcut = venue.get("shortcut", "")
        venue_type = venue.get("type", "")
        
        if venue_type == "conference":
            venue_badge = f'<div class="badge-conference">{shortcut} {year}</div>'
            if venue.get("ccf"):
                ccf_badge = f'<div class="badge-ccf badge-ccf-{venue["ccf"].lower()}">CCF {venue["ccf"]}</div>'
        else:
            venue_badge = f'<div class="badge-journal">{shortcut}</div>'
            if venue.get("sci"):
                impact = venue.get("impact_factor", "")
                if_text = f" | IF: {impact}" if impact else ""
                ccf_badge = f'<div class="badge-impact badge-q1">SCI {venue["sci"]}{if_text}</div>'
    
    # ç”Ÿæˆé«˜å¼•ç”¨å¾½ç« 
    citation_badge = ""
    if citations >= 50:
        citation_badge = f' <span class="citation-badge">{citations} citations</span>'
    
    # æ ¼å¼åŒ–ä½œè€…ï¼ˆé«˜äº®è‡ªå·±ï¼‰
    formatted_authors = authors
    for variant in AUTHOR_NAME_VARIANTS:
        formatted_authors = formatted_authors.replace(variant, f"**{variant}**")
    
    # ç”Ÿæˆ Markdown
    md = f"""<div class='paper-box'><div class='paper-box-image'><div>{venue_badge}{ccf_badge}<img src='images/placeholder.png' alt="paper" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[{title}]({link}){citation_badge} \\\\
{venue.get('shortcut', 'Publication')} | {year} \\\\
{formatted_authors}

<!-- TODO: Add paper description -->

</div>
</div>
"""
    return md


def generate_papers_json(papers: list, output_path: str):
    """
    ä¿å­˜è®ºæ–‡æ•°æ®ä¸º JSON
    """
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(papers, f, ensure_ascii=False, indent=2)
    print(f"[OK] è®ºæ–‡æ•°æ®å·²ä¿å­˜åˆ° {output_path}")


def generate_papers_markdown(papers: list, output_path: str):
    """
    ç”Ÿæˆè®ºæ–‡ Markdown æ–‡ä»¶
    """
    # ç­›é€‰åº”è¯¥åŒ…å«çš„è®ºæ–‡
    included_papers = [p for p in papers if p["should_include"]]
    
    # æŒ‰å¹´ä»½å’Œå¼•ç”¨æ•°æ’åº
    included_papers.sort(key=lambda x: (-int(x.get("year", 0) or 0), -x.get("citations", 0)))
    
    # åˆ†ç±»ï¼šæœŸåˆŠå’Œä¼šè®®
    journal_papers = [p for p in included_papers if p.get("venue", {}).get("type") == "journal"]
    conference_papers = [p for p in included_papers if p.get("venue", {}).get("type") == "conference"]
    other_papers = [p for p in included_papers if not p.get("venue")]
    
    # ç”Ÿæˆ Markdown
    md_content = """# ğŸ“ Auto-Generated Publications

> This file is auto-generated from Google Scholar data.
> Papers included: First-author papers with CCF B+/SCI Q2+ or 50+ citations.

---

"""
    
    if journal_papers:
        md_content += "## ğŸ“° Journal Articles\n\n"
        for paper in journal_papers:
            md_content += generate_paper_markdown(paper) + "\n"
    
    if conference_papers:
        md_content += "## ğŸ“ Conference Papers\n\n"
        for paper in conference_papers:
            md_content += generate_paper_markdown(paper) + "\n"
    
    if other_papers:
        md_content += "## ğŸ“„ Other Publications\n\n"
        for paper in other_papers:
            md_content += generate_paper_markdown(paper) + "\n"
    
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(md_content)
    
    print(f"[OK] Markdown æ–‡ä»¶å·²ä¿å­˜åˆ° {output_path}")
    print(f"     åŒ…å« {len(included_papers)} ç¯‡è®ºæ–‡ ({len(journal_papers)} æœŸåˆŠ, {len(conference_papers)} ä¼šè®®)")


def main():
    """ä¸»å‡½æ•°"""
    scholar_id = os.environ.get("GOOGLE_SCHOLAR_ID", "hCvlj5cAAAAJ")
    serpapi_key = os.environ.get("SERPAPI_KEY", "")
    
    if not serpapi_key:
        print("[ERROR] SERPAPI_KEY æœªè®¾ç½®")
        return 1
    
    print("=" * 60)
    print("è®ºæ–‡ä¿¡æ¯è‡ªåŠ¨ç”Ÿæˆå™¨")
    print("=" * 60)
    
    # è·å–è®ºæ–‡åˆ—è¡¨
    articles = get_author_articles(scholar_id, serpapi_key)
    
    if not articles:
        print("[ERROR] æ— æ³•è·å–è®ºæ–‡åˆ—è¡¨")
        return 1
    
    # å¤„ç†è®ºæ–‡
    processed_papers = process_papers(articles)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("results", exist_ok=True)
    
    # ä¿å­˜ JSON
    generate_papers_json(processed_papers, "results/all_papers.json")
    
    # ç­›é€‰ç¬¦åˆæ¡ä»¶çš„è®ºæ–‡
    qualified = [p for p in processed_papers if p["should_include"]]
    generate_papers_json(qualified, "results/qualified_papers_detail.json")
    
    # ç”Ÿæˆ Markdown
    generate_papers_markdown(processed_papers, "results/auto_publications.md")
    
    # è¾“å‡ºæ‘˜è¦
    print("\n" + "=" * 60)
    print("ç»Ÿè®¡æ‘˜è¦:")
    print(f"  æ€»è®ºæ–‡æ•°: {len(processed_papers)}")
    print(f"  ä¸€ä½œè®ºæ–‡æ•°: {len([p for p in processed_papers if p['is_first_author']])}")
    print(f"  é«˜å¼•ç”¨è®ºæ–‡ (>=50): {len([p for p in processed_papers if p['is_high_cited']])}")
    print(f"  ç¬¦åˆæ¡ä»¶çš„è®ºæ–‡: {len(qualified)}")
    print("=" * 60)
    
    return 0


if __name__ == "__main__":
    sys.exit(main())

